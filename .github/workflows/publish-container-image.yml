name: Publish Image to GHCR
on:
  push:
    branches:
      - main
    paths-ignore:
      - "**.md"
      - "**.txt"
  schedule:
    - cron: "0 0 * * 0"

jobs:
  build:
    runs-on: ubuntu-24.04
    strategy:
      fail-fast: false
      matrix:
        model:
          - Llama-3.2-1B-Instruct
          - Llama-3.2-3B-Instruct
          - Qwen2.5-0.5B-Instruct
          - Qwen2.5-1.5B-Instruct
          - Qwen2.5-3B-Instruct
          - Qwen2.5-Coder-0.5B-Instruct
          - Qwen2.5.1-Coder-1.5B-Instruct
          - Qwen2.5-Coder-3B-Instruct
          - Qwen2.5-Math-1.5B-Instruct
          - Yi-Coder-1.5B
          - Yi-Coder-1.5B-Chat
          - granite-3.0-1b-a400m-instruct
          - granite-3.0-2b-instruct
          - granite-3.0-3b-a800m-instruct
          - SmolLM2-135M-Instruct
          - SmolLM2-360M-Instruct
          - SmolLM2-1.7B-Instruct
          - Phi-3.5-mini-instruct
          - Nemotron-Mini-4B-Instruct
          - AMD-OLMo-1B-SFT-DPO

    steps:
      - name: Checkout Repository
        uses: actions/checkout@v4

      #      - name: Set up QEMU
      #        uses: docker/setup-qemu-action@v3

      - name: Convert model name to lowercase
        id: change_case
        uses: ASzc/change-string-case-action@v6
        with:
          string: ${{ matrix.model }}

      - name: Build Image with Buildah
        id: build_image
        uses: redhat-actions/buildah-build@v2
        with:
          containerfiles: ./Containerfile
          image: llama-server
          #          archs: amd64, arm64
          tags: ${{ steps.change_case.outputs.lowercase }}
          build-args: MODEL=${{ matrix.model }}
          labels: |
            io.artifacthub.package.readme-url=https://raw.githubusercontent.com/${{ github.repository }}/main/README.md
            org.opencontainers.image.url=https://github.com/${{ github.repository }}
            org.opencontainers.image.description=${{ matrix.model }}-Q4_0_8_8.gguf
            org.opencontainers.image.source=https://huggingface.co/bartowski/${{ matrix.model }}-GGUF

      - name: Run Image
        run:  podman run -d -p 8001:8080 llama-server:${{ steps.change_case.outputs.lowercase }}

      - name: Test response
        run: curl http://127.0.0.1:8001/v1/chat/completions -H "Content-Type: application/json" -d '{"messages":[{"role":"user","content":"Why is the sky blue?"}]}'

      - name: Push Image to GHCR
        uses: redhat-actions/push-to-registry@v2
        with:
          image: ${{ steps.build_image.outputs.image }}
          tags: ${{ steps.build_image.outputs.tags }}
          registry: ghcr.io/${{ github.repository_owner }}
          username: ${{ github.actor }}
          password: ${{ secrets.GITHUB_TOKEN }}

  prune-untagged:
    runs-on: ubuntu-24.04
    needs: build
    steps:
      - name: Prune Untagged Images
        uses: quartx-analytics/ghcr-cleaner@v1
        with:
          owner-type: user
          token: ${{ secrets.PAT_TOKEN }}
          repository-owner: ${{ github.repository_owner }}
          package-name: llama-server
          delete-untagged: true
